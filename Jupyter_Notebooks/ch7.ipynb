{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas \n",
    "import pandas as pd\n",
    "\n",
    "# Read the data using csv\n",
    "data = pd.read_csv('../Data/employee.csv')\n",
    "\n",
    "# See initial 5 records\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See last 5 records\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print list of columns in the data\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of a DataFrame\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the information of DataFrame\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the descriptive statistics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Dataframe\n",
    "# Filter columns \n",
    "data.filter(['name', 'department'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Series\n",
    "# Filter column “name”\n",
    "data['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Dataframe, because the category name was entered in a list\n",
    "# Filter column “name” \n",
    "data[['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter two columns: name and department\n",
    "data[['name','department']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows for specific index\n",
    "data.filter([0,1,2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data using slicing\n",
    "data[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for specific value \n",
    "data[data.department=='Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data for multiple values\n",
    "data[data.department.isin(['Sales','Finance'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter employee who has more than 700 performance score\n",
    "data[(data.performance_score >=700)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter employee who has more than 500 and less than 700 performance score\n",
    "data[(data.performance_score >=500) & (data.performance_score < 700)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter employee who has performance score less than 500\n",
    "data.query('performance_score<500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing value rows using dropna() function\n",
    "# Read the data\n",
    "data=pd.read_csv('employee.csv')\n",
    "data=data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data=pd.read_csv('employee.csv')\n",
    "\n",
    "# Fill all the missing values in the age column with mean of the age column\n",
    "data['age']=data.age.fillna(data.age.mean())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all the missing values in the income column with a median of the income column\n",
    "data['income']=data.income.fillna(data.income.median())\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all the missing values in the gender column(category column) with the mode of the gender column\n",
    "data['gender']=data['gender'].fillna(data['gender'].mode()[0])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data=pd.read_csv('employee.csv')\n",
    "\n",
    "# Dropping the outliers using Standard Deviation\n",
    "upper_limit= data['performance_score'].mean () + 3 * data['performance_score'].std ()\n",
    "lower_limit = data['performance_score'].mean () - 3 * data['performance_score'].std () \n",
    "data = data[(data['performance_score'] < upper_limit) & (data['performance_score'] > lower_limit)]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data=pd.read_csv('employee.csv')\n",
    "\n",
    "# Drop the outlier observations using Percentiles\n",
    "upper_limit = data['performance_score'].quantile(.99)\n",
    "lower_limit = data['performance_score'].quantile(.01)\n",
    "data = data[(data['performance_score'] < upper_limit) & (data['performance_score'] > lower_limit)]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data=pd.read_csv('../Data/employee.csv')\n",
    "# Dummy encoding\n",
    "encoded_data = pd.get_dummies(data['gender'])\n",
    "\n",
    "# Join the encoded _data with original dataframe\n",
    "data = data.join(encoded_data)\n",
    "\n",
    "# Check the top-5 records of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import one hot encoder  \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "data = pd.read_csv('../Data/employee.csv')\n",
    "  \n",
    "# Initialize the one hot encoder object\n",
    "onehotencoder = OneHotEncoder() \n",
    "\n",
    "# Fill all the missing values in income column(category column) with mode of age column\n",
    "data['gender']=data['gender'].fillna(data['gender'].mode()[0])\n",
    "print(f\"data: \\n{data}\")\n",
    "\n",
    "# Fit and transforms the gender column\n",
    "onehotencoder.fit_transform(data[['gender']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas  \n",
    "import pandas as pd\n",
    "# Read the data\n",
    "data=pd.read_csv('../Data/employee.csv')\n",
    "# Import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Instantiate the Label Encoder Object\n",
    "label_encoder = LabelEncoder()\n",
    "# Fit and transform the column\n",
    "encoded_data = label_encoder.fit_transform(data['department'])\n",
    "# Print the encoded\n",
    "print(encoded_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inverse encoding\n",
    "inverse_encode=label_encoder.inverse_transform([0, 0, 1, 2])\n",
    "# Print inverse encode\n",
    "print(inverse_encode) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas and OrdinalEncoder\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Load the data\n",
    "data=pd.read_csv('../Data/employee.csv')\n",
    "\n",
    "# Initialize OrdinalEncoder with order \n",
    "order_encoder=OrdinalEncoder(categories=['G0','G1','G2','G3','G4'])\n",
    "\n",
    "# fit and transform the grade \n",
    "data['grade_encoded'] = label_encoder.fit_transform(data['grade'])\n",
    "\n",
    "# Check top-5 records of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StandardScaler(or z-score normalization) \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "  \n",
    "# Initialize the StandardScaler \n",
    "scaler = StandardScaler() \n",
    "  \n",
    "# To scale data \n",
    "scaler.fit(data['performance_score'].values.reshape(-1,1)) \n",
    "data['performance_std_scaler']=scaler.transform(data['performance_score'].values.reshape(-1,1))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialise the MinMaxScaler \n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# To scale data \n",
    "scaler.fit(data['performance_score'].values.reshape(-1,1)) \n",
    "data['performance_minmax_scaler']=scaler.transform(data['performance_score'].values.reshape(-1,1))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RobustScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Initialise the RobustScaler \n",
    "scaler = RobustScaler()\n",
    "\n",
    "# To scale data \n",
    "scaler.fit(data['performance_score'].values.reshape(-1,1)) \n",
    "data['performance_robust_scaler']=scaler.transform(data['performance_score'].values.reshape(-1,1))\n",
    "# See initial 5 records\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data=pd.read_csv('../Data/employee.csv')\n",
    "# Create performance grade function \n",
    "def performance_grade(score):\n",
    "    if score>=700:\n",
    "        return 'A'\n",
    "    elif score<700 and score >= 500:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'C'\n",
    "# Apply performance grade function on whole DataFrame using apply() function.    \n",
    "data['performance_grade']=data.performance_score.apply(performance_grade)    \n",
    "# See initial 5 records\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the name column in first and last name\n",
    "data['first_name']=data.name.str.split(\" \").map(lambda var: var[0])\n",
    "data['last_name']=data.name.str.split(\" \").map(lambda var: var[1])\n",
    "# Check top-5 records \n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
